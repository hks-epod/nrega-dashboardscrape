{
 "metadata": {
  "name": "",
  "signature": "sha256:1b9310b0c44cb3b30a18613e59ef20e0c12768c21695625376894f1aea38611b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "import pandas as pd\n",
      "import ast\n",
      "import time\n",
      "import datetime\n",
      "\n",
      "df = pd.read_csv('./Intermediate/errors.csv', skiprows=[0], names=['state_code', 'district_code', 'block_code', 'year', 'url', 'error_code', 'timestamp'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "base_dir = './Intermediate/'\n",
      "blocks = {\"2012-2013\" : pd.read_csv(base_dir + \"Blocks1213.csv\", index_col=False),\n",
      "          \"2013-2014\" : pd.read_csv(base_dir + \"Blocks1314.csv\", index_col=False),\n",
      "          \"2014-2015\" : pd.read_csv(base_dir + \"Blocks1415.csv\", index_col=False)}\n",
      "\n",
      "states = {\"2012-2013\" : pd.read_csv(base_dir + \"States1213.csv\", index_col=False),\n",
      "          \"2013-2014\" : pd.read_csv(base_dir + \"States1314.csv\", index_col=False),\n",
      "          \"2014-2015\" : pd.read_csv(base_dir + \"States1415.csv\", index_col=False)}\n",
      "\n",
      "url_stub = 'http://164.100.129.6/netnrega/nrega-reportdashboard/api/dashboard_report_monthly.aspx?'\n",
      "\n",
      "rows = []\n",
      "errors = []\n",
      "fail_count = 0\n",
      "\n",
      "for i, row in df.iterrows(): \n",
      "    year = row.year\n",
      "    er_state = row.state_code\n",
      "    er_district = row.district_code\n",
      "    er_block = row.block_code\n",
      "    \n",
      "    if row.error_code == \"STATE_FAILURE\":\n",
      "        fail_count = 0\n",
      "        for block in blocks[year][blocks[year][\"state\"] == er_state][\"block\"]:\n",
      "            #add leading zeroes\n",
      "            state_code =    str(blocks[year][blocks[year][\"block\"] == block][\"state\"].values[0]).zfill(2)\n",
      "            district_code = str(blocks[year][blocks[year][\"block\"] == block][\"district\"].values[0]).zfill(4)\n",
      "            block_code = str(blocks[year][blocks[year][\"block\"] == block][\"block\"].values[0]).zfill(7)\n",
      "\n",
      "            #create URL\n",
      "            url = url_stub + 'state_code=' \\\n",
      "                + state_code + '&district_code=' \\\n",
      "                + district_code + '&block_code=' \\\n",
      "                + block_code + '&fin_year=' \\\n",
      "                + year + '&type=b'\n",
      "            \n",
      "            #add timestamp\n",
      "            ts = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
      "\n",
      "            #parse page returns\n",
      "            try:\n",
      "                if fail_count <=3:\n",
      "                    site_text = requests.get(url, timeout=(5.0, 10.0)).text #query and get the text on the site\n",
      "                    data = ast.literal_eval(site_text)[0] #evaluate the text as python code\n",
      "                    if data == [{}]:\n",
      "                            print \"Empty dictionary returned for state %s, district %s, and block %s for year %s\" % (state_code, district_code, block_code, year)\n",
      "                            errors.append([state_code, district_code, block_code, year, url, \"EMPTY\"])\n",
      "                    else:                    \t\n",
      "                        data['state_code'] = state_code\n",
      "                        data['district_code'] = district_code\n",
      "                        data['block_code'] = block_code\n",
      "                        data['year'] = year\n",
      "                        data['timestamp'] = ts\n",
      "                        rows.append(data)\n",
      "                        time.sleep(0.5)\n",
      "                else:\n",
      "                    print \"State %s is being skipped for year %s for too many failures\" % (state_code, year)\n",
      "                    del errors[-4:]\n",
      "                    errors.append([state_code, \"ALL\", \"ALL\", year, \"ALL\",\"STATE_FAILURE\", ts])\n",
      "                    break\n",
      "\n",
      "            except requests.exceptions.ConnectTimeout as e:\n",
      "                print \"Server too slow to connect for state %s, district %s, and block %s for year %s\" % (state_code, district_code, block_code, year)\n",
      "                errors.append([state_code, district_code, block_code, year, url, \"TIMEOUT\", ts])\n",
      "                fail_count += 1\n",
      "            except requests.exceptions.ReadTimeout as e:\n",
      "                print \"Server too slow to read for state %s, district %s, and block %s for year %s\" % (state_code, district_code, block_code, year)\n",
      "                errors.append([state_code, district_code, block_code, year, url, \"TIMEOUT\", ts])\n",
      "                fail_count += 1\n",
      "            except:\n",
      "                print \"Could not access page for state %s, district %s, and block %s for year %s\" % (state_code, district_code, block_code, year)\n",
      "                errors.append([state_code, district_code, block_code, year, url, \"NO_ACCESS\", ts])\n",
      "                fail_count += 1\n",
      "                \n",
      "    else: \n",
      "        #add leading zeroes\n",
      "        state_code = er_state\n",
      "        district_code = er_district\n",
      "        block_code = er_block\n",
      "        url = row.url\n",
      "\n",
      "        #add timestamp\n",
      "        ts = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d %H:%M:%S')\n",
      "\n",
      "        #parse page returns\n",
      "        try:\n",
      "            if fail_count <=3:\n",
      "                site_text = requests.get(url, timeout=(5.0, 10.0)).text #query and get the text on the site\n",
      "                data = ast.literal_eval(site_text)[0] #evaluate the text as python code\n",
      "                if data == [{}]:\n",
      "                        print \"Empty dictionary returned for state %s, district %s, and block %s for year %s\" % (state_code, district_code, block_code, year)\n",
      "                        errors.append([state_code, district_code, block_code, year, url, \"EMPTY\"])\n",
      "                else:                    \t\n",
      "                    data['state_code'] = state_code\n",
      "                    data['district_code'] = district_code\n",
      "                    data['block_code'] = block_code\n",
      "                    data['year'] = year\n",
      "                    data['timestamp'] = ts\n",
      "                    rows.append(data)\n",
      "                    time.sleep(0.5)\n",
      "            \n",
      "            else:\n",
      "                print \"State %s is being skipped for year %s for too many failures\" % (state_code, year)\n",
      "                del errors[-4:]\n",
      "                errors.append([state_code, \"ALL\", \"ALL\", year, \"ALL\",\"STATE_FAILURE\", ts])\n",
      "                break\n",
      "            \n",
      "        except requests.exceptions.ConnectTimeout as e:\n",
      "            print \"Server too slow to connect for state %s, district %s, and block %s for year %s\" % (state_code, district_code, block_code, year)\n",
      "            errors.append([state_code, district_code, block_code, year, url, \"TIMEOUT\", ts])\n",
      "            fail_count += 1\n",
      "        except requests.exceptions.ReadTimeout as e:\n",
      "            print \"Server too slow to read for state %s, district %s, and block %s for year %s\" % (state_code, district_code, block_code, year)\n",
      "            errors.append([state_code, district_code, block_code, year, url, \"TIMEOUT\", ts])\n",
      "            fail_count += 1\n",
      "        except:\n",
      "            print \"Could not access page for state %s, district %s, and block %s for year %s\" % (state_code, district_code, block_code, year)\n",
      "            errors.append([state_code, district_code, block_code, year, url, \"NO_ACCESS\", ts])\n",
      "            fail_count += 1\n",
      "    \n",
      "pd.DataFrame(rows).to_csv('./Intermediate/retry_successes.csv', index=False)     \n",
      "pd.DataFrame(errors).to_csv('./Intermediate/errors.csv', index=False) #should overwrite as we have a new list of errors now!\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Server too slow to read for state 11, district 1105, and block 1105009 for year 2013-2014\n",
        "Server too slow to read for state 11, district 1106, and block 1106002 for year 2013-2014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Server too slow to read for state 11, district 1106, and block 1106004 for year 2013-2014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Server too slow to read for state 11, district 1115, and block 1115008 for year 2013-2014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "State 11 is being skipped for year 2013-2014 for too many failures\n",
        "Server too slow to read for state 02, district 0201, and block 0201021 for year 2013-2014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Server too slow to read for state 02, district 0201, and block 0201024 for year 2013-2014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Server too slow to read for state 02, district 0201, and block 0201026 for year 2013-2014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Server too slow to read for state 02, district 0201, and block 0201029 for year 2013-2014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "State 02 is being skipped for year 2013-2014 for too many failures\n",
        "Server too slow to read for state 33, district 3308, and block 3308002 for year 2013-2014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Server too slow to read for state 33, district 3309, and block 3309004 for year 2013-2014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Server too slow to read for state 33, district 3313, and block 3313003 for year 2013-2014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Server too slow to read for state 33, district 3313, and block 3313004 for year 2013-2014"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "State 33 is being skipped for year 2013-2014 for too many failures\n"
       ]
      },
      {
       "ename": "IOError",
       "evalue": "[Errno 13] Permission denied: './Intermediate/retry_successes.csv'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-28-b39f969f9d61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mfail_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Intermediate/retry_successes.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Intermediate/errors2.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#should overwrite as we have a new list of errors now!\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mseflek\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\util\\decorators.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mseflek\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, **kwds)\u001b[0m\n\u001b[0;32m   1152\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m                                      escapechar=escapechar)\n\u001b[1;32m-> 1154\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mseflek\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\core\\format.pyc\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m             f = com._get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m-> 1375\u001b[1;33m                                 encoding=self.encoding)\n\u001b[0m\u001b[0;32m   1376\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\mseflek\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\pandas\\core\\common.pyc\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path, mode, encoding, compression)\u001b[0m\n\u001b[0;32m   2667\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2669\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2671\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIOError\u001b[0m: [Errno 13] Permission denied: './Intermediate/retry_successes.csv'"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pd.DataFrame(rows).to_csv('./Intermediate/retry_successes.csv', index=False)     \n",
      "pd.DataFrame(errors).to_csv('./Intermediate/errors2.csv', index=False) #should overwrite as we have a new list of errors now!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}